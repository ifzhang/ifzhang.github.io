<!doctype html>
<html>

<head>
<title>Yifu Zhang</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Yifu Zhang"> 
<meta name="description" content="Yifu Zhang's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />


</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Yifu Zhang 张一夫<h1>
				</div>

		<p>
                    I am a third-year (2019-now) M.S. student at Huazhong University of Science and Technology, supervised by Prof. <a href="https://xinggangw.info/">Xinggang Wang</a> and Prof. <a href="http://eic.hust.edu.cn/professor/liuwenyu/">Wenyu Liu</a>. My research interest is computer vision, especially multi-object tracking. </br>
                <p>
		    I obtained my bachelor degree from Huazhong University of Science and Technology. I interned at IM Group of Microsoft Research Aisa, mentored by <a href="https://www.chunyuwang.org/">Chunyu Wang</a>. I also interned at ByteDance, mentored by <a href="https://miracle-fmh.github.io//">Dongdong Yu</a>.
			</br>
		</p>  
	        <p>
		    <a href="https://github.com/ifzhang">Github</a> | <a href="https://scholar.google.com/citations?user=MBxFzjcAAAAJ&hl=zh-CN">Google Scholar</a> | <a href="https://www.linkedin.com/in/yifuzhang-6589b71a2/">Linkedin</a> </br>
		    Email: zhangyifu0829 AT gmail DOT com </br>
		</p>
		
			</td>

			</td>
			<td width="25%">
				<img src="assets/imgs/yifuzhang.jpg" width="100%"/>
			</td>
		<tr>
	</tbody>
</table>


<h2>News</h2>
<!-- <ul> -->
    [2022/03] We are organizing <a href="https://motcomplex.github.io/">Multiple Object Tracking and Segmentation in Complex Environments Workshop</a>, ECCV 2022.
<!-- </ul> -->


<h2>Publications</h2>
<!-- <ul>     -->
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
          <img src="assets/imgs/voxeltrack.jpg" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          VoxelTrack: Multi-Person 3D Human Pose Estimation and Tracking in the Wild
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Yifu Zhang</b>, Chunyu Wang, Xinggang Wang, Wenyu Liu, Wenjun Zeng 
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2022
          <p>
          [<a href="https://arxiv.org/abs/2108.02452" target="_blank" rel="noopener">paper</a>]
          </p>
      </div>
    </div>

    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
          <img src="assets/imgs/fairmot.jpg" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          FairMOT: On the Fairness of Detection and Re-Identification in Multi-Object Tracking
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Yifu Zhang</b>*, Chunyu Wang*, Xinggang Wang, Wenjun Zeng, Wenyu Liu
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          International Journal of Computer Vision (<b>IJCV</b>), 2021
          <p>
          [<a href="https://arxiv.org/abs/2004.01888" target="_blank" rel="noopener">paper</a>]
          [<a href="https://github.com/ifzhang/FairMOT" target="_blank" rel="noopener">code</a>]
          </p>
      </div>
    </div>


<h2>Preprints</h2>
<!-- <ul>     -->
    <div class="paper" style="clear:left;">
      <div class="pimg" style="float:left;margin-bottom:10px;padding-left:3px;border-bottom:solid 1px #EEE;box-shadow:0 0px 2px">
          <img src="assets/imgs/bytetrack.jpg" width="200" >
      </div>
      <div class="ptitle" style="padding:1px;margin-left:215px;">
          ByteTrack: Multi-Object Tracking by Associating Every Detection Box
      </div>
      <div class="pauthors" style="padding:1px;margin-left:215px;">
          <b>Yifu Zhang</b>, Peize Sun, Yi Jiang, Dongdong Yu, Fucheng Weng, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang
      </div>
      <div class="pvenue" style="padding:1px;margin-left:215px;">
          arXiv:2110.06864
          <p>
          [<a href="https://arxiv.org/abs/2110.06864" target="_blank" rel="noopener">paper</a>]
          [<a href="https://github.com/ifzhang/ByteTrack" target="_blank" rel="noopener">code</a>] 
          </p>
      </div>
    </div>


<h2>Academic Service</h2>

<ul>
    <li>
        Conference Reviewer: CVPR 2022, ECCV 2022 </br>
    </li>

    <li>
        Journal Reviewer: IJCV, TCSVT, Pattern Recognition, Neurocomputing, NCAA</br> 
    </li>

    <li>
	Workshop Organizer: <a href="https://motcomplex.github.io/">Multiple Object Tracking and Segmentation in Complex Environments Workshop</a>, ECCV 2022.
    </li>
</ul>

<table width="100%"> 
	<tr> 
		<td align="center">&copy; Yifu Zhang | Last update: April 2022</td>
	</tr> 
</table>

</div>


</body>

</html>
